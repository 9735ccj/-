{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_ch():\n",
    "    from pylab import mpl\n",
    "    mpl.rcParams['font.sans-serif'] = ['FangSong'] # 指定默认字体\n",
    "    mpl.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "set_ch()\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.notebook_repr_html',True)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',150)\n",
    "pd.set_option('display.max_seq_items',None)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def test_model(dfs, results, names):#返回模型误差，R²,每个用户最好的模型\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    from sklearn import cross_validation\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    from sklearn import cross_validation, metrics\n",
    "    from statsmodels.tsa.arima_model import ARIMA\n",
    "    from xgboost import XGBRegressor\n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    err_df = pd.DataFrame(index=['Linear_','Ridge_','Lasso_','ElasticNet_','CART_err_','RForest_','GBRT_','ExtraTree_','XGB_','Ada_'])\n",
    "    corrcoef_df = pd.DataFrame(index=['Linear_','Ridge_','Lasso_','ElasticNet_','CART_err_','RForest_','GBRT_','ExtraTree_','XGB_','Ada_'])\n",
    "    \n",
    "    models = []\n",
    "    best_models = {}\n",
    "    best_models_name = {}\n",
    "    best_errdf = {}\n",
    "    models.append(('Linear_err', LinearRegression()))\n",
    "    models.append(('Ridge_err', Ridge()))\n",
    "    models.append(('Lasso_err', Lasso()))\n",
    "    models.append(('EticNet_err', ElasticNet()))\n",
    "    models.append(('CART_err', DecisionTreeRegressor()))\n",
    "    models.append(('RF_err', RandomForestRegressor()))\n",
    "    models.append(('GBRT_err', GradientBoostingRegressor()))\n",
    "    models.append(('Extrtree_err', ExtraTreesRegressor()))\n",
    "    models.append(('Xgboost_err', XGBRegressor()))\n",
    "    models.append(('Ada_err', AdaBoostRegressor()))\n",
    "\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        best_err = 1000000000\n",
    "\n",
    "        err = []\n",
    "        corrcoef = []\n",
    "        #print rr,'\\t\\t','corrcoef_df\\t','err'\n",
    "        for name, model in models:\n",
    "            model.fit(X_train, Y_train)\n",
    "            Y_pred = model.predict(X_test)\n",
    "\n",
    "            sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "            sum_ = np.sum(sum_)\n",
    "            sum_ = sum_ / 8.0\n",
    "            sum_ = math.sqrt(sum_)\n",
    "            corr = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "            corrcoef.append(corr)\n",
    "            err.append(sum_)\n",
    "            if sum_ < best_err:\n",
    "                best_err = sum_ \n",
    "                best_models[rr] = model\n",
    "                best_models_name[rr] = name[:-4]\n",
    "            #print name,':\\tR²=','%.3f'%corr,'\\terr=','%.3f'%sum_\n",
    "        #print '\\n'\n",
    "        corrcoef_df[rr]=corrcoef\n",
    "        err_df[rr] = err\n",
    "        best_errdf[rr] = '%.3f'%best_err\n",
    "    model_df = pd.DataFrame({'model':best_models,'model_name':best_models_name,'err':best_errdf})\n",
    "    return err_df,corrcoef_df,model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*- \n",
    "def handle_data(data,monthnums):#传入的data为dataframe类型，data需第一列为时间，第二列开始为用户，且行数不得小于30,数据需从1月份开始,monthnums为所需预测的月份\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    name = data.columns[1:]\n",
    "\n",
    "    global usernum#用户数量\n",
    "    global userdata_rows#用户数据行数\n",
    "    global train_num\n",
    "    global test_num\n",
    "    global train_test_num\n",
    "    global lastmonth#用户所给数据的最后一个年月\n",
    "    global firstmonth#用户所给数据的第一个年月\n",
    "    global start_pre_month#预测开始年月\n",
    "    global end_pre_month#预测结束年月\n",
    "    global lastmonth_month#用户所给数据的最后一个年月的月份\n",
    "    global firstmonth_month#用户所给数据的第一个年月的月份\n",
    "    \n",
    "    usernum = data.shape[1]-1\n",
    "    userdata_rows = data.shape[0]\n",
    "    train_test_num = userdata_rows-15#训练集加上测试集的大小\n",
    "    train_num = int(train_test_num*0.85)#训练集大小\n",
    "    test_num = train_test_num-train_num#测试集大小\n",
    "    lastmonth = data['year'].values[-1]\n",
    "    firstmonth = data['year'].values[0]\n",
    "    start_pre_month = data['year'].values[-int(test_num)]\n",
    "    end_pre_month = int(lastmonth)+monthnums\n",
    "    lastmonth_month = int(lastmonth[-2]+lastmonth[-1])\n",
    "    firstmonth_month = int(firstmonth[-2]+firstmonth[-1])\n",
    "    \n",
    "    #print '用户所给的最后一个年月数据:',lastmonth\n",
    "    #print '用户所给的第一个年月数据:',firstmonth\n",
    "    #print '预测开始年月：',start_pre_month\n",
    "    #print '预测结束年月:',end_pre_month\n",
    "    \n",
    "    \n",
    "    yuce_month = int(start_pre_month[-2]+start_pre_month[-1])#预测开始月份,从哪里开始截取表格\n",
    "    if yuce_month>firstmonth_month:\n",
    "        yuce_year = (int(lastmonth)-int(data['year'].values[yuce_month-firstmonth_month]))/100#表格需要增加的年份\n",
    "        yuce = data[yuce_month-firstmonth_month:yuce_month-firstmonth_month+test_num+monthnums].copy()#建立表格，后面改数据\n",
    "    else:\n",
    "        yuce_year = (int(lastmonth)-int(data['year'].values[yuce_month+(12-firstmonth_month)]))/100\n",
    "        yuce = data[yuce_month+(12-firstmonth_month):yuce_month+(12-firstmonth_month)+test_num+monthnums].copy()\n",
    "    yuce.year =yuce.year.astype('int') + yuce_year*100\n",
    "    \n",
    "    dfs = {}\n",
    "    results = {}\n",
    "    for rr in name:\n",
    "        train = data[rr]\n",
    "        tt = np.zeros((train_test_num, 10))\n",
    "\n",
    "        result = []\n",
    "        index = 0\n",
    "        for i in range(15, userdata_rows):\n",
    "            result.append(train[i])\n",
    "            tt[index][0] = train[i - 1]\n",
    "            tt[index][1] = train[i - 2]\n",
    "            tt[index][2] = train[i - 3]\n",
    "            tt[index][3] = train[i - 1] + train[i - 2] + train[i - 3]\n",
    "\n",
    "            tt[index][4] = np.mean(train[i - 3:i])\n",
    "            tt[index][5] = np.var(train[i - 3:i])\n",
    "\n",
    "            tt[index][6] = train[i - 12]\n",
    "            tt[index][7] = train[i - 12 - 1]\n",
    "            tt[index][8] = train[i - 12 - 2]\n",
    "\n",
    "            tt[index][9] = (i + 1) % 12\n",
    "            index += 1\n",
    "        df = pd.DataFrame(tt,\n",
    "                          columns=['month_1', 'month_2', 'month_3', 'month_sum', 'month_mean', 'month_var', 'lastmonth_1',\n",
    "                                   'lastmonth_2', 'lastmonth_3', 'month_date'])\n",
    "\n",
    "        lastmonth_sum = np.sum(df.iloc[:, 6:9], axis=1)\n",
    "        df['lastmonth_sum'] = lastmonth_sum\n",
    "\n",
    "        lastmonth_mean = np.mean(df.iloc[:, 6:9], axis=1)\n",
    "        df['lastmonth_mean'] = lastmonth_mean\n",
    "        lastmonth_var = np.var(df.iloc[:, 6:9], axis=1)\n",
    "        df['lastmonth_var'] = lastmonth_var\n",
    "\n",
    "        dummy_1 = pd.get_dummies(df['month_date'], prefix='month_date')#转化为one-hot编码\n",
    "        df.drop(['month_date'], axis=1, inplace=True)\n",
    "        df = pd.concat([df, dummy_1], axis=1)\n",
    "        dfs[rr] = df\n",
    "        results[rr] = result\n",
    "    return dfs, results,yuce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def predict_front(dataframe,monthnums,modelnum=0):#dataframe,预测月份数，模型选择,modelnum默认为0，即自动选择用户最优模型\n",
    "    import matplotlib as plt\n",
    "    dfs, results, yuce = handle_data(dataframe,monthnums)#获取处理后的数据,训练集，结果集，未修改的预测表格\n",
    "\n",
    "    names = dataframe.columns[1:]\n",
    "    err_df,corrcoef_df,model_df = test_model(dfs, results, names)\n",
    "\n",
    "    user_best_df = pd.DataFrame({'bestmodel':model_df['model_name'],'err':model_df['err']})\n",
    "    \n",
    "    if modelnum==0:\n",
    "        for rr in names:\n",
    "            names = [rr]\n",
    "            model_post=user_best_df['bestmodel'][rr]\n",
    "            locals()['best_models_'+model_post] , locals()['y_predictions_'+model_post] , locals()['err_'+model_post] = eval(model_post)(dfs=dfs,results=results,names=names)\n",
    "            yuce = predict_behind(best_models=locals()['best_models_'+model_post],y_predictions=locals()['y_predictions_'+model_post],results=results,names=names,yuce=yuce,monthnums=monthnums)\n",
    "            print '针对用户',rr[-1],':\\t',model_post,'最佳模型预测完毕'\n",
    "            print locals()['err_'+model_post] \n",
    "        return yuce\n",
    "    elif modelnum==1:\n",
    "        model_post = 'Extrtree'\n",
    "    elif modelnum==2:\n",
    "        model_post = 'RF'\n",
    "    elif modelnum==3:\n",
    "        model_post = 'Xgboost'\n",
    "    elif modelnum==4:\n",
    "        model_post = 'Linear'\n",
    "    elif modelnum==5:\n",
    "        model_post = 'GBRT'\n",
    "    elif modelnum==6:\n",
    "        model_post = 'Ada'\n",
    "    elif modelnum==7:\n",
    "        model_post = 'CART'\n",
    "    elif modelnum==8:\n",
    "        model_post = 'EticNet'\n",
    "    elif modelnum==9:\n",
    "        model_post = 'Lasso'\n",
    "    elif modelnum==10:\n",
    "        model_post = 'Ridge'\n",
    "        \n",
    "    print '数据预测中...请稍等...'\n",
    "    locals()['best_models_'+model_post] , locals()['y_predictions_'+model_post] , locals()['err_'+model_post] = eval(model_post)(dfs=dfs,results=results,names=names)\n",
    "    yuce = predict_behind(best_models=locals()['best_models_'+model_post],y_predictions=locals()['y_predictions_'+model_post],results=results,names=names,yuce=yuce,monthnums=monthnums)\n",
    "    print model_post,'模型预测完毕'\n",
    "    print locals()['err_'+model_post] \n",
    "    \n",
    "    return yuce\n",
    "    #users_models_err , corrcoef_df ,modle_df= test_model(dfs = dfs, results = results, names = names)#获取最佳模型及模型误差/模型的可决系数\n",
    "    #print modle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Ada(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = AdaBoostRegressor()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Ada_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"Ada_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def CART(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = DecisionTreeRegressor()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"CART_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"CART_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def EticNet(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = ElasticNet()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"ElasticNet_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"ElasticNet_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Lasso(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = Lasso()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Lasso_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"Lasso_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Ridge(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = Ridge()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Ridge_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"Ridge_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def GBRT(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = GradientBoostingRegressor()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"GBRT_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"GBRT_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Linear(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "        sum_ = np.sum(sum_)\n",
    "        sum_ = sum_ / 8.0\n",
    "        err = math.sqrt(sum_)\n",
    "        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "        abs_err = err\n",
    "        best_model = model\n",
    "        y_prediction = Y_pred\n",
    "        \n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Linear_model/%s_train_model.m\"%rr)\n",
    "        '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"Linear_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "        #'''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def RF(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "\n",
    "        #'''\n",
    "        #learn_rate = 0\n",
    "        feature_rate = 0\n",
    "        nestimator = 0\n",
    "        max_depth = 0 \n",
    "        samples_leaf = 0\n",
    "        model_yuce = 0\n",
    "        for n_round in [150,250,400]:\n",
    "            for depth in [5,6]:\n",
    "                for leaf in [1,2]: \n",
    "                    model = RandomForestRegressor(criterion='mse', max_depth = depth,\n",
    "                          max_features='auto',  min_samples_leaf=leaf,\n",
    "                          min_samples_split=2, n_estimators=  n_round, random_state=1126)\n",
    "\n",
    "                    model.fit(X_train, Y_train)\n",
    "                    #y_trainpre = model.predict(X_train)\n",
    "                    Y_pred = model.predict(X_test)\n",
    "                        #msg = \"%s: \" % (name)\n",
    "                        #print(rr)\n",
    "                        #err = metrics.mean_absolute_error(y_test, y_pred)\n",
    "                    sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "                    sum_ = np.sum(sum_)\n",
    "                    sum_ = sum_ / 8.0\n",
    "                    err = math.sqrt(sum_)\n",
    "                    #err_p.append(sum)\n",
    "                    #print (msg),\" \\t%.4g\" % sum_#metrics.mean_absolute_error(y_test, y_pred)  \n",
    "                    if err < abs_err:\n",
    "                        r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "                        abs_err = err\n",
    "                        best_model = model\n",
    "                        y_prediction = Y_pred\n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"RF_model/%s_train_model.m\"%rr)\n",
    "    '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"RF_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "    '''     \n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Extrtree(dfs,results,names):#返回参数最佳模型，并且返回训练时候的预测结果\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.ensemble import ExtraTreesRegressor\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "\n",
    "        ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
    "              max_features='auto', max_leaf_nodes=None, min_samples_leaf=1,\n",
    "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "              n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "              verbose=0, warm_start=False)\n",
    "        #'''\n",
    "        #learn_rate = 0\n",
    "        feature_rate = 0\n",
    "        nestimator = 0\n",
    "        max_depth = 0 \n",
    "        samples_leaf = 0\n",
    "        model_yuce = 0\n",
    "        for n_round in [150,250,400]:\n",
    "            for feature in [0.9,1.0]:\n",
    "                for depth in [5,6]:\n",
    "                    for leaf in [1,2]: \n",
    "                        model = ExtraTreesRegressor(criterion='mse', max_depth = depth,\n",
    "                              max_features=feature,  min_samples_leaf=leaf,\n",
    "                              min_samples_split=2, n_estimators=  n_round, random_state=1126)\n",
    "\n",
    "                        model.fit(X_train, Y_train)\n",
    "                        #y_trainpre = model.predict(X_train)\n",
    "                        Y_pred = model.predict(X_test)\n",
    "                            #msg = \"%s: \" % (name)\n",
    "                            #print(rr)\n",
    "                            #err = metrics.mean_absolute_error(y_test, y_pred)\n",
    "                        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "                        sum_ = np.sum(sum_)\n",
    "                        sum_ = sum_ / 8.0\n",
    "                        err = math.sqrt(sum_)\n",
    "                        #err_p.append(sum)\n",
    "                        #print (msg),\" \\t%.4g\" % sum_#metrics.mean_absolute_error(y_test, y_pred)  \n",
    "                        if err < abs_err:\n",
    "                            r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "                            abs_err = err\n",
    "                            best_model = model\n",
    "                            y_prediction = Y_pred\n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Extr_model/%s_train_model.m\"%rr)\n",
    "    '''\n",
    "    #使用训练好的模型\n",
    "        model = joblib.load(\"Extr_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "        global feathername\n",
    "        feathername = X_train.columns\n",
    "    '''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def Xgboost(dfs,results,names):\n",
    "    from xgboost import XGBRegressor\n",
    "    import numpy as np\n",
    "    import math\n",
    "    from sklearn.externals import joblib\n",
    "    best_models = {}\n",
    "    y_predictions = {}\n",
    "    errs = {}\n",
    "    num=0.0\n",
    "    for rr in names:\n",
    "        user_dfs = dfs[rr]\n",
    "        \n",
    "        y_prediction = []\n",
    "        X_train = user_dfs[0:train_num]\n",
    "        Y_train = results[rr][0:train_num]\n",
    "\n",
    "        X_test = user_dfs[train_num:train_test_num]\n",
    "        Y_test = results[rr][train_num:train_test_num]\n",
    "        abs_err = 1000000000\n",
    "        #需要调用保存好的模型则从这里开始注释掉\n",
    "        #'''\n",
    "        #learn_rate = 0\n",
    "        feature_rate = 0\n",
    "        nestimator = 0\n",
    "        max_depth = 0 \n",
    "        samples_leaf = 0\n",
    "        model_yuce = 0\n",
    "        for lr in [0.1,0.05,0.01,0.005]:\n",
    "            for n_estimator in [300,500,800,1000]:\n",
    "                for max_depth in [4,5,6]:\n",
    "                    for min_child_weight in [1,2,3,4,5,6]:\n",
    "                                        model = XGBRegressor(learning_rate =lr,n_estimators=n_estimator ,max_depth=max_depth,min_child_weight=min_child_weight,gamma=1,subsample=1.0,\n",
    "                                        colsample_bytree=1.0,reg_alpha=1.0,objective= 'reg:linear',nthread=-1,scale_pos_weight=1,seed=1126)\n",
    "                                        eval_set = [(X_test, Y_test)]\n",
    "                                        model.fit(X_train, Y_train, eval_metric=['rmse'], eval_set=eval_set,verbose=False,early_stopping_rounds = 30)\n",
    "                                        #y_trainpre = model.predict(X_train)\n",
    "                                        Y_pred = model.predict(X_test)\n",
    "                                                #msg = \"%s: \" % (name)\n",
    "                                                #print(rr)\n",
    "                                                #err = metrics.mean_absolute_error(y_test, y_pred)\n",
    "                                        sum_  =  ( (Y_test - Y_pred) /(Y_test)) *  (  ((Y_test - Y_pred) ) / (Y_test) )#( abs((predict_1[r] - real[r+1])) / (real[r + 1] * 1.0) ) \n",
    "                                        sum_ = np.sum(sum_)\n",
    "                                        sum_ = sum_ / 8.0\n",
    "                                        err = math.sqrt(sum_)\n",
    "                                        #err_p.append(sum)\n",
    "                                        #print (msg),\" \\t%.4g\" % sum_#metrics.mean_absolute_error(y_test, y_pred)  \n",
    "                                        if err < abs_err:\n",
    "                                                r2 = np.corrcoef(Y_pred,Y_test,rowvar=0)[0,1]\n",
    "                                                abs_err = err\n",
    "                                                best_model = model\n",
    "                                                y_prediction = Y_pred\n",
    "        num = num+1\n",
    "        #print '参数训练：',num*100/len(names),'%'\n",
    "        best_models[rr]=best_model\n",
    "        y_predictions[rr]=y_prediction\n",
    "        errs[rr]=abs_err\n",
    "    for rr in names:\n",
    "        joblib.dump(best_models[rr], \"Xgb_model/%s_train_model.m\"%rr)#保存训练模型\n",
    "    '''\n",
    "    #读取使用训练好的模型，为了方便测试而已\n",
    "        model = joblib.load(\"Xgb_model/%s_train_model.m\"%rr)\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_prediction = Y_pred\n",
    "        best_models[rr]=model\n",
    "        y_predictions[rr]=y_prediction\n",
    "    \n",
    "        #print '%s_train_score:'%rr,model.score(X_train,Y_train)\n",
    "        #print '%s_test_score:'%rr,model.score(X_test,Y_test),'\\n'\n",
    "    '''\n",
    "    return best_models,y_predictions,errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "def predict_behind(best_models,y_predictions,results,names,yuce,monthnums):#最佳模型，训练时候预测的结果，用户数据,用户名字,待填入的表格,预测的月份数\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    for rr in names:\n",
    "        model = best_models[rr]\n",
    "        y_prediction = y_predictions[rr].tolist()\n",
    "        result = results[rr]\n",
    "        for d in range(lastmonth_month+1,lastmonth_month+monthnums+1):\n",
    "            val = []\n",
    "            val.append(result[-1])\n",
    "            val.append(result[-2])\n",
    "            val.append(result[-3])\n",
    "\n",
    "            dd1 = np.sum(result[-3:])\n",
    "            dd2 = np.mean(result[-3:])\n",
    "            dd3 = np.var(result[-3:])\n",
    "\n",
    "            val.append(dd1)\n",
    "            val.append(dd2)\n",
    "            val.append(dd3)\n",
    "\n",
    "            val.append(result[-13])\n",
    "            val.append(result[-14])\n",
    "            val.append(result[-15])\n",
    "\n",
    "            df_1 = pd.DataFrame(np.array(val).reshape(1,9),columns=['month_1','month_2','month_3','month_sum','month_mean','month_var','lastmonth_1','lastmonth_2','lastmonth_3'])\n",
    "\n",
    "            lastmonth_sum = np.sum (df_1.iloc[:,6:9],axis = 1 )\n",
    "            df_1['lastmonth_sum'] = lastmonth_sum\n",
    "\n",
    "            lastmonth_mean = np.mean(df_1.iloc[:,6:9],axis = 1 )\n",
    "            df_1['lastmonth_mean'] = lastmonth_mean\n",
    "\n",
    "            lastmonth_var = np.var(df_1.iloc[:,6:9],axis = 1 )\n",
    "            df_1['lastmonth_var']  =  lastmonth_var\n",
    "            strs = 'month_date_'\n",
    "            for j in range(1,13):\n",
    "                d = d%12\n",
    "                if d==0:\n",
    "                    d=12\n",
    "                col= strs + str(j-1)+'.0'\n",
    "                if j == d:\n",
    "                    df_1[col] = 1\n",
    "                else:\n",
    "                    df_1[col] = 0\n",
    "            #print df_1\n",
    "            pr =model.predict(df_1)#.values)\n",
    "            y_prediction.append(pr[0])\n",
    "\n",
    "            result.append(pr[0])\n",
    "        yuce[rr] = y_prediction#此处修改表格\n",
    "    return yuce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "针对用户 l :\tXgboost 最佳模型预测完毕\n",
      "{'total': 0.06737014930347388}\n",
      "针对用户 A :\tExtrtree 最佳模型预测完毕\n",
      "{'UserA': 0.06048218937123648}\n",
      "针对用户 B :\tXgboost 最佳模型预测完毕\n",
      "{'UserB': 0.0667111196852653}\n",
      "针对用户 C :\tExtrtree 最佳模型预测完毕\n",
      "{'UserC': 0.09232319531917232}\n",
      "针对用户 D :\tGBRT 最佳模型预测完毕\n",
      "{'UserD': 0.07719744214418763}\n",
      "针对用户 F :\tExtrtree 最佳模型预测完毕\n",
      "{'UserF': 0.08164922363673457}\n",
      "针对用户 G :\tGBRT 最佳模型预测完毕\n",
      "{'UserG': 0.0663972107310566}\n",
      "针对用户 H :\tGBRT 最佳模型预测完毕\n",
      "{'UserH': 0.05643088544705206}\n",
      "针对用户 I :\tExtrtree 最佳模型预测完毕\n",
      "{'UserI': 0.04958745194960609}\n",
      "针对用户 J :\tExtrtree 最佳模型预测完毕\n",
      "{'UserJ': 0.050872992342386486}\n",
      "针对用户 K :\tAda 最佳模型预测完毕\n",
      "{'UserK': 0.13243765296523816}\n",
      "针对用户 L :\tLasso 最佳模型预测完毕\n",
      "{'UserL': 0.1276831646307825}\n",
      "针对用户 M :\tRidge 最佳模型预测完毕\n",
      "{'UserM': 0.07156455352935115}\n",
      "针对用户 N :\tExtrtree 最佳模型预测完毕\n",
      "{'UserN': 0.0646719680466625}\n",
      "针对用户 O :\tExtrtree 最佳模型预测完毕\n",
      "{'UserO': 0.1068069611761291}\n",
      "针对用户 P :\tAda 最佳模型预测完毕\n",
      "{'UserP': 0.12266658254508242}\n",
      "针对用户 Q :\tGBRT 最佳模型预测完毕\n",
      "{'UserQ': 0.17906108897486028}\n",
      "针对用户 R :\tEticNet 最佳模型预测完毕\n",
      "{'UserR': 0.07386824097124475}\n",
      "针对用户 S :\tEticNet 最佳模型预测完毕\n",
      "{'UserS': 0.21790077103867758}\n",
      "针对用户 T :\tExtrtree 最佳模型预测完毕\n",
      "{'UserT': 0.09082173856206048}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>total</th>\n",
       "      <th>UserA</th>\n",
       "      <th>UserB</th>\n",
       "      <th>UserC</th>\n",
       "      <th>UserD</th>\n",
       "      <th>UserF</th>\n",
       "      <th>UserG</th>\n",
       "      <th>UserH</th>\n",
       "      <th>UserI</th>\n",
       "      <th>UserJ</th>\n",
       "      <th>UserK</th>\n",
       "      <th>UserL</th>\n",
       "      <th>UserM</th>\n",
       "      <th>UserN</th>\n",
       "      <th>UserO</th>\n",
       "      <th>UserP</th>\n",
       "      <th>UserQ</th>\n",
       "      <th>UserR</th>\n",
       "      <th>UserS</th>\n",
       "      <th>UserT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>201601</td>\n",
       "      <td>15979988.0</td>\n",
       "      <td>3.051912e+06</td>\n",
       "      <td>1.150270e+06</td>\n",
       "      <td>191407.212980</td>\n",
       "      <td>1.635866e+06</td>\n",
       "      <td>224899.004958</td>\n",
       "      <td>144510.265020</td>\n",
       "      <td>1.354265e+06</td>\n",
       "      <td>767313.600287</td>\n",
       "      <td>208998.650259</td>\n",
       "      <td>28120.216111</td>\n",
       "      <td>813956.208213</td>\n",
       "      <td>48603.725009</td>\n",
       "      <td>194801.128969</td>\n",
       "      <td>72908.245235</td>\n",
       "      <td>3.830154e+06</td>\n",
       "      <td>403675.256263</td>\n",
       "      <td>188795.379502</td>\n",
       "      <td>198504.559395</td>\n",
       "      <td>940625.994248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>201602</td>\n",
       "      <td>12985894.0</td>\n",
       "      <td>2.160328e+06</td>\n",
       "      <td>9.711174e+05</td>\n",
       "      <td>142933.137286</td>\n",
       "      <td>1.451552e+06</td>\n",
       "      <td>205994.273438</td>\n",
       "      <td>124587.141992</td>\n",
       "      <td>1.036860e+06</td>\n",
       "      <td>630030.684465</td>\n",
       "      <td>206616.521922</td>\n",
       "      <td>29587.394286</td>\n",
       "      <td>470807.462551</td>\n",
       "      <td>49742.271828</td>\n",
       "      <td>174992.341804</td>\n",
       "      <td>71490.610076</td>\n",
       "      <td>3.281438e+06</td>\n",
       "      <td>319720.075075</td>\n",
       "      <td>174927.402561</td>\n",
       "      <td>206111.109986</td>\n",
       "      <td>621598.852339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>201603</td>\n",
       "      <td>6747719.0</td>\n",
       "      <td>1.079271e+06</td>\n",
       "      <td>4.359702e+05</td>\n",
       "      <td>81287.580000</td>\n",
       "      <td>8.304113e+05</td>\n",
       "      <td>169518.186074</td>\n",
       "      <td>72780.203037</td>\n",
       "      <td>5.389180e+05</td>\n",
       "      <td>405086.201433</td>\n",
       "      <td>103787.613333</td>\n",
       "      <td>19935.010000</td>\n",
       "      <td>329249.123418</td>\n",
       "      <td>43921.284619</td>\n",
       "      <td>110487.748400</td>\n",
       "      <td>40460.465333</td>\n",
       "      <td>2.156520e+06</td>\n",
       "      <td>246375.115785</td>\n",
       "      <td>146115.943498</td>\n",
       "      <td>94828.078891</td>\n",
       "      <td>288835.328287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>201604</td>\n",
       "      <td>12470456.0</td>\n",
       "      <td>2.587162e+06</td>\n",
       "      <td>8.811551e+05</td>\n",
       "      <td>167055.656106</td>\n",
       "      <td>1.397489e+06</td>\n",
       "      <td>181805.081550</td>\n",
       "      <td>106987.959970</td>\n",
       "      <td>1.093118e+06</td>\n",
       "      <td>642859.017173</td>\n",
       "      <td>189599.042703</td>\n",
       "      <td>27642.315556</td>\n",
       "      <td>736830.295549</td>\n",
       "      <td>50539.230316</td>\n",
       "      <td>167015.575945</td>\n",
       "      <td>68152.608878</td>\n",
       "      <td>3.124189e+06</td>\n",
       "      <td>374539.051437</td>\n",
       "      <td>182918.235495</td>\n",
       "      <td>150024.121285</td>\n",
       "      <td>726887.543609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>201605</td>\n",
       "      <td>13729152.0</td>\n",
       "      <td>2.668969e+06</td>\n",
       "      <td>1.002284e+06</td>\n",
       "      <td>168778.101530</td>\n",
       "      <td>1.416435e+06</td>\n",
       "      <td>178521.772801</td>\n",
       "      <td>126351.751933</td>\n",
       "      <td>1.121195e+06</td>\n",
       "      <td>640303.772148</td>\n",
       "      <td>192213.432478</td>\n",
       "      <td>28675.035714</td>\n",
       "      <td>832725.568996</td>\n",
       "      <td>52451.285021</td>\n",
       "      <td>170696.312695</td>\n",
       "      <td>68592.871297</td>\n",
       "      <td>3.356582e+06</td>\n",
       "      <td>334495.544922</td>\n",
       "      <td>174278.396589</td>\n",
       "      <td>219997.090698</td>\n",
       "      <td>785295.794359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>201606</td>\n",
       "      <td>14605678.0</td>\n",
       "      <td>2.712199e+06</td>\n",
       "      <td>1.015808e+06</td>\n",
       "      <td>168848.499658</td>\n",
       "      <td>1.439867e+06</td>\n",
       "      <td>214580.821299</td>\n",
       "      <td>120987.925159</td>\n",
       "      <td>1.156117e+06</td>\n",
       "      <td>708384.090289</td>\n",
       "      <td>204265.890551</td>\n",
       "      <td>29824.907647</td>\n",
       "      <td>782631.357947</td>\n",
       "      <td>58461.110606</td>\n",
       "      <td>188823.454416</td>\n",
       "      <td>71820.619524</td>\n",
       "      <td>3.504151e+06</td>\n",
       "      <td>326837.930569</td>\n",
       "      <td>179313.639990</td>\n",
       "      <td>200629.457124</td>\n",
       "      <td>832223.924543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>201607</td>\n",
       "      <td>13856424.0</td>\n",
       "      <td>2.701909e+06</td>\n",
       "      <td>1.001022e+06</td>\n",
       "      <td>172089.040289</td>\n",
       "      <td>1.451293e+06</td>\n",
       "      <td>208270.092742</td>\n",
       "      <td>119732.567873</td>\n",
       "      <td>1.137532e+06</td>\n",
       "      <td>701124.454440</td>\n",
       "      <td>208756.431519</td>\n",
       "      <td>29515.158889</td>\n",
       "      <td>744941.197094</td>\n",
       "      <td>60076.790325</td>\n",
       "      <td>194088.652491</td>\n",
       "      <td>73530.375645</td>\n",
       "      <td>3.605277e+06</td>\n",
       "      <td>329202.105729</td>\n",
       "      <td>190585.387329</td>\n",
       "      <td>169548.253612</td>\n",
       "      <td>810235.121914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>201608</td>\n",
       "      <td>13771118.0</td>\n",
       "      <td>2.723870e+06</td>\n",
       "      <td>9.727777e+05</td>\n",
       "      <td>172707.556945</td>\n",
       "      <td>1.485771e+06</td>\n",
       "      <td>211907.646541</td>\n",
       "      <td>121614.216462</td>\n",
       "      <td>1.171605e+06</td>\n",
       "      <td>716192.260008</td>\n",
       "      <td>213377.912877</td>\n",
       "      <td>29757.286364</td>\n",
       "      <td>762963.347064</td>\n",
       "      <td>60321.516217</td>\n",
       "      <td>199392.843007</td>\n",
       "      <td>73684.593561</td>\n",
       "      <td>3.776873e+06</td>\n",
       "      <td>342741.597287</td>\n",
       "      <td>200248.531597</td>\n",
       "      <td>163063.209288</td>\n",
       "      <td>814764.306365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>201609</td>\n",
       "      <td>13537708.0</td>\n",
       "      <td>2.728035e+06</td>\n",
       "      <td>9.660276e+05</td>\n",
       "      <td>177615.523482</td>\n",
       "      <td>1.438753e+06</td>\n",
       "      <td>210133.526305</td>\n",
       "      <td>117367.219262</td>\n",
       "      <td>1.171501e+06</td>\n",
       "      <td>715153.761908</td>\n",
       "      <td>212169.160802</td>\n",
       "      <td>29757.286364</td>\n",
       "      <td>782078.676518</td>\n",
       "      <td>62157.439482</td>\n",
       "      <td>203307.719675</td>\n",
       "      <td>73697.680481</td>\n",
       "      <td>3.774499e+06</td>\n",
       "      <td>302894.097812</td>\n",
       "      <td>214713.623112</td>\n",
       "      <td>167598.547413</td>\n",
       "      <td>814764.306365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>201610</td>\n",
       "      <td>13431980.0</td>\n",
       "      <td>2.715863e+06</td>\n",
       "      <td>9.646596e+05</td>\n",
       "      <td>181845.041240</td>\n",
       "      <td>1.421970e+06</td>\n",
       "      <td>206099.656885</td>\n",
       "      <td>122723.115929</td>\n",
       "      <td>1.147484e+06</td>\n",
       "      <td>712873.460088</td>\n",
       "      <td>212868.186037</td>\n",
       "      <td>29824.907647</td>\n",
       "      <td>748791.336893</td>\n",
       "      <td>64968.879911</td>\n",
       "      <td>208429.610494</td>\n",
       "      <td>73440.611002</td>\n",
       "      <td>3.602492e+06</td>\n",
       "      <td>319687.359067</td>\n",
       "      <td>214074.475602</td>\n",
       "      <td>176970.952879</td>\n",
       "      <td>822048.386548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>201611</td>\n",
       "      <td>12771444.0</td>\n",
       "      <td>2.670540e+06</td>\n",
       "      <td>9.863957e+05</td>\n",
       "      <td>179255.922744</td>\n",
       "      <td>1.434286e+06</td>\n",
       "      <td>203275.639781</td>\n",
       "      <td>118579.117021</td>\n",
       "      <td>1.132301e+06</td>\n",
       "      <td>688473.516377</td>\n",
       "      <td>206249.090429</td>\n",
       "      <td>29515.158889</td>\n",
       "      <td>733735.239942</td>\n",
       "      <td>61471.680123</td>\n",
       "      <td>203284.466048</td>\n",
       "      <td>73312.345125</td>\n",
       "      <td>3.700859e+06</td>\n",
       "      <td>333617.771986</td>\n",
       "      <td>214512.623346</td>\n",
       "      <td>173226.060674</td>\n",
       "      <td>792306.761234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>201612</td>\n",
       "      <td>13374994.0</td>\n",
       "      <td>2.609149e+06</td>\n",
       "      <td>9.432682e+05</td>\n",
       "      <td>179204.998000</td>\n",
       "      <td>1.405740e+06</td>\n",
       "      <td>205748.993121</td>\n",
       "      <td>121452.338482</td>\n",
       "      <td>1.129621e+06</td>\n",
       "      <td>675648.943054</td>\n",
       "      <td>204881.919839</td>\n",
       "      <td>30298.766667</td>\n",
       "      <td>730431.761231</td>\n",
       "      <td>59833.425649</td>\n",
       "      <td>150884.771705</td>\n",
       "      <td>73220.903059</td>\n",
       "      <td>3.451446e+06</td>\n",
       "      <td>321587.540691</td>\n",
       "      <td>207572.761778</td>\n",
       "      <td>170422.352729</td>\n",
       "      <td>801123.426083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>201701</td>\n",
       "      <td>10918286.0</td>\n",
       "      <td>1.955225e+06</td>\n",
       "      <td>6.756735e+05</td>\n",
       "      <td>157930.749099</td>\n",
       "      <td>1.042528e+06</td>\n",
       "      <td>204359.565199</td>\n",
       "      <td>116938.111999</td>\n",
       "      <td>8.296607e+05</td>\n",
       "      <td>518874.892391</td>\n",
       "      <td>208186.923271</td>\n",
       "      <td>29457.182353</td>\n",
       "      <td>581976.114938</td>\n",
       "      <td>59832.163907</td>\n",
       "      <td>128887.430511</td>\n",
       "      <td>69254.079109</td>\n",
       "      <td>2.791471e+06</td>\n",
       "      <td>223600.863538</td>\n",
       "      <td>207679.699331</td>\n",
       "      <td>154737.388408</td>\n",
       "      <td>502373.978893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>201702</td>\n",
       "      <td>15143170.0</td>\n",
       "      <td>3.051912e+06</td>\n",
       "      <td>1.150054e+06</td>\n",
       "      <td>197924.963763</td>\n",
       "      <td>1.578366e+06</td>\n",
       "      <td>223472.238394</td>\n",
       "      <td>144216.354608</td>\n",
       "      <td>1.371203e+06</td>\n",
       "      <td>756066.826849</td>\n",
       "      <td>208521.582603</td>\n",
       "      <td>30101.505714</td>\n",
       "      <td>843812.580950</td>\n",
       "      <td>56646.121512</td>\n",
       "      <td>187722.259671</td>\n",
       "      <td>73406.228324</td>\n",
       "      <td>3.864423e+06</td>\n",
       "      <td>421589.533438</td>\n",
       "      <td>215917.780808</td>\n",
       "      <td>183591.364101</td>\n",
       "      <td>942238.123788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>201703</td>\n",
       "      <td>12307040.0</td>\n",
       "      <td>2.035072e+06</td>\n",
       "      <td>9.467957e+05</td>\n",
       "      <td>141693.546067</td>\n",
       "      <td>1.449183e+06</td>\n",
       "      <td>208538.181439</td>\n",
       "      <td>121433.620099</td>\n",
       "      <td>1.001182e+06</td>\n",
       "      <td>614801.305059</td>\n",
       "      <td>202582.830841</td>\n",
       "      <td>30013.295000</td>\n",
       "      <td>475609.543520</td>\n",
       "      <td>57384.096071</td>\n",
       "      <td>174120.866382</td>\n",
       "      <td>72114.111162</td>\n",
       "      <td>3.133758e+06</td>\n",
       "      <td>299389.066774</td>\n",
       "      <td>228922.771566</td>\n",
       "      <td>190848.933171</td>\n",
       "      <td>601012.539247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>201704</td>\n",
       "      <td>6913496.0</td>\n",
       "      <td>1.071871e+06</td>\n",
       "      <td>4.106782e+05</td>\n",
       "      <td>81287.580000</td>\n",
       "      <td>8.530643e+05</td>\n",
       "      <td>175744.633398</td>\n",
       "      <td>72311.025041</td>\n",
       "      <td>5.311764e+05</td>\n",
       "      <td>401105.447889</td>\n",
       "      <td>103787.613333</td>\n",
       "      <td>19935.010000</td>\n",
       "      <td>302112.852372</td>\n",
       "      <td>50719.248923</td>\n",
       "      <td>111812.631133</td>\n",
       "      <td>41274.610980</td>\n",
       "      <td>2.156520e+06</td>\n",
       "      <td>248698.841138</td>\n",
       "      <td>211358.451031</td>\n",
       "      <td>105574.707957</td>\n",
       "      <td>288172.344327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>201705</td>\n",
       "      <td>12867212.0</td>\n",
       "      <td>2.632784e+06</td>\n",
       "      <td>9.463536e+05</td>\n",
       "      <td>168766.401072</td>\n",
       "      <td>1.438209e+06</td>\n",
       "      <td>196897.285822</td>\n",
       "      <td>101271.193293</td>\n",
       "      <td>1.082382e+06</td>\n",
       "      <td>645979.403633</td>\n",
       "      <td>192331.796874</td>\n",
       "      <td>27674.086000</td>\n",
       "      <td>720855.346848</td>\n",
       "      <td>56248.179497</td>\n",
       "      <td>183184.513011</td>\n",
       "      <td>68244.854152</td>\n",
       "      <td>3.340034e+06</td>\n",
       "      <td>373229.854357</td>\n",
       "      <td>235581.345706</td>\n",
       "      <td>162342.957230</td>\n",
       "      <td>741072.103874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>201706</td>\n",
       "      <td>13775924.0</td>\n",
       "      <td>2.672000e+06</td>\n",
       "      <td>1.018642e+06</td>\n",
       "      <td>168989.609457</td>\n",
       "      <td>1.459520e+06</td>\n",
       "      <td>179102.232490</td>\n",
       "      <td>124620.175432</td>\n",
       "      <td>1.115408e+06</td>\n",
       "      <td>636649.690694</td>\n",
       "      <td>193442.947464</td>\n",
       "      <td>28675.035714</td>\n",
       "      <td>785962.352521</td>\n",
       "      <td>55927.204296</td>\n",
       "      <td>171965.221693</td>\n",
       "      <td>68529.364540</td>\n",
       "      <td>3.358169e+06</td>\n",
       "      <td>359685.929336</td>\n",
       "      <td>237183.691256</td>\n",
       "      <td>205661.703614</td>\n",
       "      <td>821287.905091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>201707</td>\n",
       "      <td>14435688.0</td>\n",
       "      <td>2.717049e+06</td>\n",
       "      <td>9.926084e+05</td>\n",
       "      <td>169244.390700</td>\n",
       "      <td>1.461577e+06</td>\n",
       "      <td>212194.303902</td>\n",
       "      <td>121535.697138</td>\n",
       "      <td>1.153409e+06</td>\n",
       "      <td>710051.750954</td>\n",
       "      <td>207036.521989</td>\n",
       "      <td>29135.790909</td>\n",
       "      <td>777124.869461</td>\n",
       "      <td>59201.577554</td>\n",
       "      <td>191266.470423</td>\n",
       "      <td>70547.709365</td>\n",
       "      <td>3.570438e+06</td>\n",
       "      <td>326103.774292</td>\n",
       "      <td>240844.988056</td>\n",
       "      <td>186811.179315</td>\n",
       "      <td>832870.654679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>201708</td>\n",
       "      <td>14356100.0</td>\n",
       "      <td>2.710678e+06</td>\n",
       "      <td>9.734814e+05</td>\n",
       "      <td>171129.106130</td>\n",
       "      <td>1.454762e+06</td>\n",
       "      <td>207018.437965</td>\n",
       "      <td>135567.123254</td>\n",
       "      <td>1.144891e+06</td>\n",
       "      <td>711894.066492</td>\n",
       "      <td>208453.311623</td>\n",
       "      <td>29135.790909</td>\n",
       "      <td>732328.555552</td>\n",
       "      <td>63466.635519</td>\n",
       "      <td>191553.059955</td>\n",
       "      <td>71322.092630</td>\n",
       "      <td>3.776873e+06</td>\n",
       "      <td>263893.262828</td>\n",
       "      <td>241246.203253</td>\n",
       "      <td>166568.390849</td>\n",
       "      <td>810624.196375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>201709</td>\n",
       "      <td>13923190.0</td>\n",
       "      <td>2.717964e+06</td>\n",
       "      <td>9.824176e+05</td>\n",
       "      <td>171549.752661</td>\n",
       "      <td>1.435984e+06</td>\n",
       "      <td>214778.729121</td>\n",
       "      <td>121087.153196</td>\n",
       "      <td>1.103804e+06</td>\n",
       "      <td>714763.310108</td>\n",
       "      <td>213563.760243</td>\n",
       "      <td>29135.790909</td>\n",
       "      <td>755631.448315</td>\n",
       "      <td>64337.800424</td>\n",
       "      <td>198775.073448</td>\n",
       "      <td>71898.843733</td>\n",
       "      <td>3.776873e+06</td>\n",
       "      <td>383522.865781</td>\n",
       "      <td>249555.256530</td>\n",
       "      <td>166233.742678</td>\n",
       "      <td>814008.025518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>201710</td>\n",
       "      <td>13012120.0</td>\n",
       "      <td>2.713607e+06</td>\n",
       "      <td>9.998858e+05</td>\n",
       "      <td>171918.249651</td>\n",
       "      <td>1.441617e+06</td>\n",
       "      <td>206439.033129</td>\n",
       "      <td>114939.428251</td>\n",
       "      <td>1.158543e+06</td>\n",
       "      <td>712483.008288</td>\n",
       "      <td>213786.937985</td>\n",
       "      <td>29135.790909</td>\n",
       "      <td>742988.616254</td>\n",
       "      <td>68121.122417</td>\n",
       "      <td>210548.849369</td>\n",
       "      <td>73387.364281</td>\n",
       "      <td>3.769745e+06</td>\n",
       "      <td>363793.822713</td>\n",
       "      <td>248677.283789</td>\n",
       "      <td>176320.510021</td>\n",
       "      <td>820238.817693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>201711</td>\n",
       "      <td>13220508.0</td>\n",
       "      <td>2.689241e+06</td>\n",
       "      <td>9.984770e+05</td>\n",
       "      <td>171512.513268</td>\n",
       "      <td>1.459809e+06</td>\n",
       "      <td>204147.277914</td>\n",
       "      <td>120116.512861</td>\n",
       "      <td>1.070252e+06</td>\n",
       "      <td>708566.530339</td>\n",
       "      <td>206453.025862</td>\n",
       "      <td>29230.524737</td>\n",
       "      <td>711069.006662</td>\n",
       "      <td>66229.110986</td>\n",
       "      <td>208005.656482</td>\n",
       "      <td>74232.001418</td>\n",
       "      <td>3.723465e+06</td>\n",
       "      <td>337129.337928</td>\n",
       "      <td>245266.845034</td>\n",
       "      <td>179702.619918</td>\n",
       "      <td>795513.130654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>201712</td>\n",
       "      <td>13749574.0</td>\n",
       "      <td>2.628286e+06</td>\n",
       "      <td>1.004459e+06</td>\n",
       "      <td>171528.968219</td>\n",
       "      <td>1.455004e+06</td>\n",
       "      <td>205662.845795</td>\n",
       "      <td>123165.976833</td>\n",
       "      <td>1.131348e+06</td>\n",
       "      <td>695563.253932</td>\n",
       "      <td>204720.649097</td>\n",
       "      <td>29879.333000</td>\n",
       "      <td>711408.288083</td>\n",
       "      <td>66512.267845</td>\n",
       "      <td>168010.302580</td>\n",
       "      <td>73409.115352</td>\n",
       "      <td>3.602492e+06</td>\n",
       "      <td>339671.957046</td>\n",
       "      <td>243972.940125</td>\n",
       "      <td>176995.531348</td>\n",
       "      <td>802870.571051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year       total         UserA         UserB          UserC  \\\n",
       "12  201601  15979988.0  3.051912e+06  1.150270e+06  191407.212980   \n",
       "13  201602  12985894.0  2.160328e+06  9.711174e+05  142933.137286   \n",
       "14  201603   6747719.0  1.079271e+06  4.359702e+05   81287.580000   \n",
       "15  201604  12470456.0  2.587162e+06  8.811551e+05  167055.656106   \n",
       "16  201605  13729152.0  2.668969e+06  1.002284e+06  168778.101530   \n",
       "17  201606  14605678.0  2.712199e+06  1.015808e+06  168848.499658   \n",
       "18  201607  13856424.0  2.701909e+06  1.001022e+06  172089.040289   \n",
       "19  201608  13771118.0  2.723870e+06  9.727777e+05  172707.556945   \n",
       "20  201609  13537708.0  2.728035e+06  9.660276e+05  177615.523482   \n",
       "21  201610  13431980.0  2.715863e+06  9.646596e+05  181845.041240   \n",
       "22  201611  12771444.0  2.670540e+06  9.863957e+05  179255.922744   \n",
       "23  201612  13374994.0  2.609149e+06  9.432682e+05  179204.998000   \n",
       "24  201701  10918286.0  1.955225e+06  6.756735e+05  157930.749099   \n",
       "25  201702  15143170.0  3.051912e+06  1.150054e+06  197924.963763   \n",
       "26  201703  12307040.0  2.035072e+06  9.467957e+05  141693.546067   \n",
       "27  201704   6913496.0  1.071871e+06  4.106782e+05   81287.580000   \n",
       "28  201705  12867212.0  2.632784e+06  9.463536e+05  168766.401072   \n",
       "29  201706  13775924.0  2.672000e+06  1.018642e+06  168989.609457   \n",
       "30  201707  14435688.0  2.717049e+06  9.926084e+05  169244.390700   \n",
       "31  201708  14356100.0  2.710678e+06  9.734814e+05  171129.106130   \n",
       "32  201709  13923190.0  2.717964e+06  9.824176e+05  171549.752661   \n",
       "33  201710  13012120.0  2.713607e+06  9.998858e+05  171918.249651   \n",
       "34  201711  13220508.0  2.689241e+06  9.984770e+05  171512.513268   \n",
       "35  201712  13749574.0  2.628286e+06  1.004459e+06  171528.968219   \n",
       "\n",
       "           UserD          UserF          UserG         UserH          UserI  \\\n",
       "12  1.635866e+06  224899.004958  144510.265020  1.354265e+06  767313.600287   \n",
       "13  1.451552e+06  205994.273438  124587.141992  1.036860e+06  630030.684465   \n",
       "14  8.304113e+05  169518.186074   72780.203037  5.389180e+05  405086.201433   \n",
       "15  1.397489e+06  181805.081550  106987.959970  1.093118e+06  642859.017173   \n",
       "16  1.416435e+06  178521.772801  126351.751933  1.121195e+06  640303.772148   \n",
       "17  1.439867e+06  214580.821299  120987.925159  1.156117e+06  708384.090289   \n",
       "18  1.451293e+06  208270.092742  119732.567873  1.137532e+06  701124.454440   \n",
       "19  1.485771e+06  211907.646541  121614.216462  1.171605e+06  716192.260008   \n",
       "20  1.438753e+06  210133.526305  117367.219262  1.171501e+06  715153.761908   \n",
       "21  1.421970e+06  206099.656885  122723.115929  1.147484e+06  712873.460088   \n",
       "22  1.434286e+06  203275.639781  118579.117021  1.132301e+06  688473.516377   \n",
       "23  1.405740e+06  205748.993121  121452.338482  1.129621e+06  675648.943054   \n",
       "24  1.042528e+06  204359.565199  116938.111999  8.296607e+05  518874.892391   \n",
       "25  1.578366e+06  223472.238394  144216.354608  1.371203e+06  756066.826849   \n",
       "26  1.449183e+06  208538.181439  121433.620099  1.001182e+06  614801.305059   \n",
       "27  8.530643e+05  175744.633398   72311.025041  5.311764e+05  401105.447889   \n",
       "28  1.438209e+06  196897.285822  101271.193293  1.082382e+06  645979.403633   \n",
       "29  1.459520e+06  179102.232490  124620.175432  1.115408e+06  636649.690694   \n",
       "30  1.461577e+06  212194.303902  121535.697138  1.153409e+06  710051.750954   \n",
       "31  1.454762e+06  207018.437965  135567.123254  1.144891e+06  711894.066492   \n",
       "32  1.435984e+06  214778.729121  121087.153196  1.103804e+06  714763.310108   \n",
       "33  1.441617e+06  206439.033129  114939.428251  1.158543e+06  712483.008288   \n",
       "34  1.459809e+06  204147.277914  120116.512861  1.070252e+06  708566.530339   \n",
       "35  1.455004e+06  205662.845795  123165.976833  1.131348e+06  695563.253932   \n",
       "\n",
       "            UserJ         UserK          UserL         UserM          UserN  \\\n",
       "12  208998.650259  28120.216111  813956.208213  48603.725009  194801.128969   \n",
       "13  206616.521922  29587.394286  470807.462551  49742.271828  174992.341804   \n",
       "14  103787.613333  19935.010000  329249.123418  43921.284619  110487.748400   \n",
       "15  189599.042703  27642.315556  736830.295549  50539.230316  167015.575945   \n",
       "16  192213.432478  28675.035714  832725.568996  52451.285021  170696.312695   \n",
       "17  204265.890551  29824.907647  782631.357947  58461.110606  188823.454416   \n",
       "18  208756.431519  29515.158889  744941.197094  60076.790325  194088.652491   \n",
       "19  213377.912877  29757.286364  762963.347064  60321.516217  199392.843007   \n",
       "20  212169.160802  29757.286364  782078.676518  62157.439482  203307.719675   \n",
       "21  212868.186037  29824.907647  748791.336893  64968.879911  208429.610494   \n",
       "22  206249.090429  29515.158889  733735.239942  61471.680123  203284.466048   \n",
       "23  204881.919839  30298.766667  730431.761231  59833.425649  150884.771705   \n",
       "24  208186.923271  29457.182353  581976.114938  59832.163907  128887.430511   \n",
       "25  208521.582603  30101.505714  843812.580950  56646.121512  187722.259671   \n",
       "26  202582.830841  30013.295000  475609.543520  57384.096071  174120.866382   \n",
       "27  103787.613333  19935.010000  302112.852372  50719.248923  111812.631133   \n",
       "28  192331.796874  27674.086000  720855.346848  56248.179497  183184.513011   \n",
       "29  193442.947464  28675.035714  785962.352521  55927.204296  171965.221693   \n",
       "30  207036.521989  29135.790909  777124.869461  59201.577554  191266.470423   \n",
       "31  208453.311623  29135.790909  732328.555552  63466.635519  191553.059955   \n",
       "32  213563.760243  29135.790909  755631.448315  64337.800424  198775.073448   \n",
       "33  213786.937985  29135.790909  742988.616254  68121.122417  210548.849369   \n",
       "34  206453.025862  29230.524737  711069.006662  66229.110986  208005.656482   \n",
       "35  204720.649097  29879.333000  711408.288083  66512.267845  168010.302580   \n",
       "\n",
       "           UserO         UserP          UserQ          UserR          UserS  \\\n",
       "12  72908.245235  3.830154e+06  403675.256263  188795.379502  198504.559395   \n",
       "13  71490.610076  3.281438e+06  319720.075075  174927.402561  206111.109986   \n",
       "14  40460.465333  2.156520e+06  246375.115785  146115.943498   94828.078891   \n",
       "15  68152.608878  3.124189e+06  374539.051437  182918.235495  150024.121285   \n",
       "16  68592.871297  3.356582e+06  334495.544922  174278.396589  219997.090698   \n",
       "17  71820.619524  3.504151e+06  326837.930569  179313.639990  200629.457124   \n",
       "18  73530.375645  3.605277e+06  329202.105729  190585.387329  169548.253612   \n",
       "19  73684.593561  3.776873e+06  342741.597287  200248.531597  163063.209288   \n",
       "20  73697.680481  3.774499e+06  302894.097812  214713.623112  167598.547413   \n",
       "21  73440.611002  3.602492e+06  319687.359067  214074.475602  176970.952879   \n",
       "22  73312.345125  3.700859e+06  333617.771986  214512.623346  173226.060674   \n",
       "23  73220.903059  3.451446e+06  321587.540691  207572.761778  170422.352729   \n",
       "24  69254.079109  2.791471e+06  223600.863538  207679.699331  154737.388408   \n",
       "25  73406.228324  3.864423e+06  421589.533438  215917.780808  183591.364101   \n",
       "26  72114.111162  3.133758e+06  299389.066774  228922.771566  190848.933171   \n",
       "27  41274.610980  2.156520e+06  248698.841138  211358.451031  105574.707957   \n",
       "28  68244.854152  3.340034e+06  373229.854357  235581.345706  162342.957230   \n",
       "29  68529.364540  3.358169e+06  359685.929336  237183.691256  205661.703614   \n",
       "30  70547.709365  3.570438e+06  326103.774292  240844.988056  186811.179315   \n",
       "31  71322.092630  3.776873e+06  263893.262828  241246.203253  166568.390849   \n",
       "32  71898.843733  3.776873e+06  383522.865781  249555.256530  166233.742678   \n",
       "33  73387.364281  3.769745e+06  363793.822713  248677.283789  176320.510021   \n",
       "34  74232.001418  3.723465e+06  337129.337928  245266.845034  179702.619918   \n",
       "35  73409.115352  3.602492e+06  339671.957046  243972.940125  176995.531348   \n",
       "\n",
       "            UserT  \n",
       "12  940625.994248  \n",
       "13  621598.852339  \n",
       "14  288835.328287  \n",
       "15  726887.543609  \n",
       "16  785295.794359  \n",
       "17  832223.924543  \n",
       "18  810235.121914  \n",
       "19  814764.306365  \n",
       "20  814764.306365  \n",
       "21  822048.386548  \n",
       "22  792306.761234  \n",
       "23  801123.426083  \n",
       "24  502373.978893  \n",
       "25  942238.123788  \n",
       "26  601012.539247  \n",
       "27  288172.344327  \n",
       "28  741072.103874  \n",
       "29  821287.905091  \n",
       "30  832870.654679  \n",
       "31  810624.196375  \n",
       "32  814008.025518  \n",
       "33  820238.817693  \n",
       "34  795513.130654  \n",
       "35  802870.571051  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.externals import joblib\n",
    "data = pd.read_csv('user.csv',sep=',',parse_dates=[0])\n",
    "data2 = pd.DataFrame(data['year'][11:51])\n",
    "data2['UserB']=data['UserB'][11:51]\n",
    "data2['UserC']=data['UserC'][11:51]\n",
    "data2['UserD']=data['UserD'][11:51]\n",
    "data2['UserF']=data['UserF'][11:51]\n",
    "data2 = data2.reset_index(drop=True)#重置索引\n",
    "\n",
    "#print data2\n",
    "yuce = predict_front(data,16,0)\n",
    "yuce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw(treemodel,feature_names):\n",
    "    from IPython.display import Image,display\n",
    "    from sklearn import tree\n",
    "    import pydotplus \n",
    "    dot_data = tree.export_graphviz(treemodel, out_file=None, \n",
    "                         feature_names=feature_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    graph.write_pdf('RF_tree3.pdf')\n",
    "    display(Image(graph.create_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yuce.to_csv('electpre_XGB_model.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserA\n"
     ]
    }
   ],
   "source": [
    "names = data.columns[1:]\n",
    "for rr in names[1:2]:\n",
    "    print rr\n",
    "    '''\n",
    "    model = joblib.load(\"Extr_model/%s_train_model.m\"%rr)\n",
    "    mytree = model.estimators_[5]\n",
    "    draw(mytree,feathername)\n",
    "    \n",
    "    print feathername\n",
    "    model2 = joblib.load(\"RF_model/%s_train_model.m\"%rr)\n",
    "    mytree2 = model2.estimators_[37]\n",
    "    draw(mytree2,feathername)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: ['UserK', 'UserM', 'UserO'], 6: ['UserB', 'UserC', 'UserF', 'UserG', 'UserI', 'UserJ', 'UserL', 'UserN', 'UserQ', 'UserR', 'UserS', 'UserT'], 7: ['UserA', 'UserD', 'UserH', 'UserP']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "test = pd.read_csv('originalData.csv',sep=',',parse_dates=[0]) \n",
    "test2 = test.drop(test.columns[[0,1]],axis=1) \n",
    "\n",
    "my = test2.apply(lambda x: x.mean())\n",
    "\n",
    "my_dict = {}\n",
    "\n",
    "for i in my.index:\n",
    "    bit = len(str(int(my[i])))\n",
    "    if my_dict.has_key(bit):\n",
    "        my_dict[bit].append(i)\n",
    "    else:\n",
    "        my_dict[bit] = [i]\n",
    "print my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [2]}\n",
      "{1: [2, 3]}\n"
     ]
    }
   ],
   "source": [
    "dic = {1:[2]}\n",
    "print dic\n",
    "dic[1].append(3)\n",
    "print dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "UserA : 8\n",
    "UserB : 8\n",
    "UserC : 7\n",
    "UserD : 8\n",
    "UserF : 7\n",
    "UserG : 7\n",
    "UserH : 8\n",
    "UserI : 8\n",
    "UserJ : 7\n",
    "UserK : 6\n",
    "UserL : 8\n",
    "UserM : 7\n",
    "UserN : 7\n",
    "UserO : 7\n",
    "UserP : 8\n",
    "UserQ : 7\n",
    "UserR : 7\n",
    "UserS : 7\n",
    "UserT : 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}